#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆè¯­éŸ³åŠ©æ‰‹APIæœåŠ¡å™¨ - GPUå†…å­˜ä¼˜åŒ–ç‰ˆ
- æ”¯æŒWhisper-large-v3-turboæ¨¡å‹ï¼Œæ˜¾å­˜å ç”¨æ›´å°‘
- ä¼˜åŒ–GPUå†…å­˜ç®¡ç†ï¼Œæ”¯æŒå¤šæ¨¡å‹å…±å­˜
- ä¼˜å…ˆæ‰§è¡ŒæŒ‡ä»¤ï¼Œè·³è¿‡AIå›å¤é¿å…GPUå†²çª
- é›†æˆModelScopeå¿«é€Ÿä¸‹è½½
"""

from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import whisper
import requests
import os
import platform
import subprocess
import tempfile
import uvicorn
from pydantic import BaseModel
from typing import Optional, List
import logging
import torch
import re
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨å°†åœ¨åé¢å®šä¹‰ï¼Œé¿å…é‡å¤

# å…¨å±€å˜é‡
whisper_model = None
OLLAMA_API_BASE = "http://localhost:11434/api"

class VoiceRequest(BaseModel):
    text: str
    execute_commands: bool = True

class VoiceResponse(BaseModel):
    transcribed_text: str
    ai_response: str
    command_executed: bool = False
    command_result: Optional[str] = None
    command_type: Optional[str] = None

# æ‰©å±•çš„æŒ‡ä»¤è¯†åˆ«è¯å…¸
COMMAND_PATTERNS = {
    "åº”ç”¨ç¨‹åº": {
        "keywords": ["æ‰“å¼€", "å¯åŠ¨", "è¿è¡Œ", "å¼€å¯"],
        "targets": {
            "è®°äº‹æœ¬": ["è®°äº‹æœ¬", "notepad", "æ–‡æœ¬ç¼–è¾‘å™¨"],
            "è®¡ç®—å™¨": ["è®¡ç®—å™¨", "calculator", "è®¡æ—¶å™¨", "è®¡æ—¶ç‰ˆ", "è®¡ç®—æœº"],
            "ç”»å›¾": ["ç”»å›¾", "ç”»æ¿", "ç»˜å›¾", "paint"],
            "æ–‡ä»¶ç®¡ç†å™¨": ["æ–‡ä»¶ç®¡ç†å™¨", "èµ„æºç®¡ç†å™¨", "æ–‡ä»¶å¤¹", "explorer"],
            "æµè§ˆå™¨": ["æµè§ˆå™¨", "browser", "ç½‘é¡µ", "ä¸Šç½‘"],
            "ä»»åŠ¡ç®¡ç†å™¨": ["ä»»åŠ¡ç®¡ç†å™¨", "è¿›ç¨‹ç®¡ç†", "task manager"],
            "æ§åˆ¶é¢æ¿": ["æ§åˆ¶é¢æ¿", "è®¾ç½®", "ç³»ç»Ÿè®¾ç½®"],
            "å‘½ä»¤æç¤ºç¬¦": ["å‘½ä»¤æç¤ºç¬¦", "cmd", "ç»ˆç«¯", "æ§åˆ¶å°"],
            "PowerShell": ["powershell", "ps", "power shell"]
        }
    },
    "ç½‘ç«™": {
        "keywords": ["æ‰“å¼€", "è®¿é—®", "è¿›å…¥", "å»", "çœ‹çœ‹"],
        "targets": {
            "ç™¾åº¦": ["ç™¾åº¦", "baidu"],
            "è°·æ­Œ": ["è°·æ­Œ", "google", "æœç´¢"],
            "çŸ¥ä¹": ["çŸ¥ä¹", "zhihu"],
            "å¾®åš": ["å¾®åš", "weibo"],
            "å“”å“©å“”å“©": ["å“”å“©å“”å“©", "bilibili", "bç«™", "Bç«™"],
            "æ·˜å®": ["æ·˜å®", "taobao", "è´­ç‰©"],
            "äº¬ä¸œ": ["äº¬ä¸œ", "jd", "å•†åŸ"],
            "GitHub": ["github", "ä»£ç ", "å¼€æº"],
            "YouTube": ["youtube", "æ²¹ç®¡", "è§†é¢‘"],
            "ç½‘æ˜“äº‘éŸ³ä¹": ["ç½‘æ˜“äº‘", "éŸ³ä¹", "æ­Œæ›²"]
        }
    },
    "ç³»ç»Ÿæ“ä½œ": {
        "keywords": ["å…³é—­", "é€€å‡º", "ç»“æŸ", "åœæ­¢", "é‡å¯", "å…³æœº", "é”å±", "ä¼‘çœ ", "å¾…æœº", "ç¡çœ ", "æˆªå›¾"],
        "targets": {
            "å…³æœº": ["å…³æœº", "shutdown", "å…³é—­ç”µè„‘"],
            "é‡å¯": ["é‡å¯", "restart", "é‡æ–°å¯åŠ¨"],
            "æ³¨é”€": ["æ³¨é”€", "logout", "ç™»å‡º"],
            "é”å±": ["é”å±", "lock", "é”å®šå±å¹•"],
            "ä¼‘çœ ": ["ä¼‘çœ ", "sleep", "å¾…æœº", "ç¡çœ "],
            "æˆªå›¾": ["æˆªå›¾", "screenshot", "å±å¹•æˆªå›¾"]
        }
    },
    "æ–‡ä»¶æ“ä½œ": {
        "keywords": ["æ–°å»º", "åˆ›å»º", "åˆ é™¤", "å¤åˆ¶", "ç§»åŠ¨"],
        "targets": {
            "æ–°å»ºæ–‡ä»¶å¤¹": ["æ–°å»ºæ–‡ä»¶å¤¹", "åˆ›å»ºæ–‡ä»¶å¤¹", "å»ºæ–‡ä»¶å¤¹"],
            "æ–°å»ºæ–‡ä»¶": ["æ–°å»ºæ–‡ä»¶", "åˆ›å»ºæ–‡ä»¶", "å»ºæ–‡ä»¶"],
            "æˆªå›¾": ["æˆªå›¾", "æˆªå±", "æŠ“å›¾", "screenshot"]
        }
    }
}

from contextlib import asynccontextmanager



@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    global whisper_model
    logger.info("ğŸš€ æ­£åœ¨å¯åŠ¨ä¼˜åŒ–ç‰ˆè¯­éŸ³åŠ©æ‰‹APIæœåŠ¡...")
    
    logger.info("ğŸ“¥ å¼€å§‹åŠ è½½Whisperæ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼‰...")
    
    # å¯¼å…¥å¿…è¦çš„æ¨¡å—
    import torch
    import whisper
    import gc
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logger.info(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device == "cuda":
        logger.info(f"ğŸ® GPUä¿¡æ¯: {torch.cuda.get_device_name(0)}")
        logger.info(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # ä¼˜å…ˆä½¿ç”¨turboæ¨¡å‹ä»¥èŠ‚çœGPUå†…å­˜
    model_priority = ["large-v3-turbo", "large-v3", "large-v2", "medium", "base"]
    
    for i, model_name in enumerate(model_priority):
        try:
            logger.info(f"ğŸ“¦ å°è¯•åŠ è½½ Whisper {model_name} æ¨¡å‹... ({i+1}/{len(model_priority)})")
            
            # æä¾›æ¨¡å‹å¤§å°ä¿¡æ¯
            model_sizes = {
                "large-v3-turbo": "1.5GB",  # turboç‰ˆæœ¬æ˜¾å­˜å ç”¨æ›´å°‘
                "large-v3": "3.1GB",
                "large-v2": "3.1GB", 
                "large": "3.1GB",
                "medium": "1.5GB",
                "base": "290MB"
            }
            
            if model_name in model_sizes:
                logger.info(f"ğŸ“Š æ¨¡å‹å¤§å°: {model_sizes[model_name]}")
                if i == 0:
                    logger.info("ğŸ’¡ æç¤º: é¦–æ¬¡ä¸‹è½½å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œæ¨¡å‹ä¼šç¼“å­˜åˆ°æœ¬åœ°")
                    logger.info("ğŸŒ ä½¿ç”¨å®˜æ–¹æºä¸‹è½½ (å¯èƒ½è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…)")
            
            # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            logger.info("â³ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œè¯·ç¨å€™...")
            if i == 0:
                logger.info("ğŸ’¡ é¦–æ¬¡ä¸‹è½½å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
                logger.info("ğŸŒ å¦‚æœä¸‹è½½å¾ˆæ…¢ï¼Œå¯ä»¥æŒ‰ Ctrl+C ä¸­æ–­ï¼Œç¨åé‡è¯•")
            
            # æ¸…ç†GPUå†…å­˜
            if device == "cuda":
                torch.cuda.empty_cache()
                gc.collect()
            
            # ç‰¹æ®Šå¤„ç†turboæ¨¡å‹ - ç›´æ¥ä»æ–‡ä»¶åŠ è½½
            if model_name == "large-v3-turbo":
                turbo_path = Path.home() / ".cache" / "whisper" / "large-v3-turbo.pt"
                if turbo_path.exists():
                    logger.info(f"ğŸ¯ ç›´æ¥åŠ è½½turboæ¨¡å‹æ–‡ä»¶: {turbo_path}")
                    whisper_model = whisper.load_model(str(turbo_path), device=device)
                else:
                    logger.warning(f"âš ï¸ turboæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {turbo_path}")
                    continue
            else:
                # åŠ è½½å®˜æ–¹æ¨¡å‹
                whisper_model = whisper.load_model(
                    model_name, 
                    device=device,
                    in_memory=True  # ä¿æŒåœ¨å†…å­˜ä¸­ä»¥æé«˜æ€§èƒ½
                )
            
            # å¦‚æœæ˜¯GPUæ¨¡å¼ï¼Œè®¾ç½®å†…å­˜åˆ†é…ç­–ç•¥
            if device == "cuda":
                # è®¾ç½®æ›´ä¿å®ˆçš„å†…å­˜åˆ†é…ï¼Œä¸ºå…¶ä»–æ¨¡å‹é¢„ç•™æ›´å¤šç©ºé—´
                torch.cuda.set_per_process_memory_fraction(0.5)  # åªä½¿ç”¨50%GPUå†…å­˜
                logger.info("ğŸ”§ GPUå†…å­˜åˆ†é…: 50% (ä¸ºå…¶ä»–AIæ¨¡å‹é¢„ç•™50%)")
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ Whisper {model_name} æ¨¡å‹åˆ° {device}")
            
            # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
            if hasattr(whisper_model, 'dims'):
                logger.info(f"ğŸ”§ æ¨¡å‹å‚æ•°: {whisper_model.dims}")
            
            break
        except Exception as e:
            logger.warning(f"âŒ æ— æ³•åŠ è½½ {model_name} æ¨¡å‹: {e}")
            if i < len(model_priority) - 1:
                logger.info(f"ğŸ”„ å°è¯•åŠ è½½ä¸‹ä¸€ä¸ªæ¨¡å‹...")
            continue
    
    if whisper_model is None:
        logger.error("ğŸ’¥ æ‰€æœ‰æ¨¡å‹åŠ è½½å¤±è´¥ï¼")
        raise RuntimeError("æ— æ³•åŠ è½½ä»»ä½•Whisperæ¨¡å‹")
    
    logger.info("ğŸ‰ è¯­éŸ³åŠ©æ‰‹APIæœåŠ¡å¯åŠ¨å®Œæˆï¼")
    logger.info(f"ğŸŒ æœåŠ¡åœ°å€: http://localhost:8889")
    logger.info(f"ğŸ“š APIæ–‡æ¡£: http://localhost:8889/docs")
    
    yield  # åº”ç”¨è¿è¡ŒæœŸé—´
    
    # å…³é—­æ—¶æ‰§è¡Œ
    logger.info("ğŸ›‘ æ­£åœ¨å…³é—­è¯­éŸ³åŠ©æ‰‹APIæœåŠ¡...")

# é‡æ–°åˆ›å»ºFastAPIåº”ç”¨ï¼Œæ­£ç¡®è®¾ç½®lifespanå‚æ•°
app = FastAPI(
    title="ä¼˜åŒ–ç‰ˆè¯­éŸ³åŠ©æ‰‹API", 
    version="2.0.0",
    description="æ”¯æŒGPUåŠ é€Ÿçš„ä¸­æ–‡è¯­éŸ³è¯†åˆ«å’Œæ™ºèƒ½æŒ‡ä»¤æ‰§è¡Œ",
    lifespan=lifespan
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "ä¼˜åŒ–ç‰ˆè¯­éŸ³åŠ©æ‰‹APIæœåŠ¡æ­£åœ¨è¿è¡Œ", "status": "healthy"}

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    device_info = "GPU" if torch.cuda.is_available() else "CPU"
    return {
        "status": "healthy", 
        "whisper_loaded": whisper_model is not None,
        "device": device_info,
        "model_info": str(whisper_model) if whisper_model else None
    }

def preprocess_chinese_text(text: str) -> str:
    """é¢„å¤„ç†ä¸­æ–‡æ–‡æœ¬ï¼Œä¿®æ­£å¸¸è§è¯†åˆ«é”™è¯¯"""
    corrections = {
        # å¸¸è§çš„ä¸­æ–‡è¯†åˆ«é”™è¯¯ä¿®æ­£
        "è®¡æ—¶ç‰ˆ": "è®°äº‹æœ¬",
        "è®¡æ—¶å™¨": "è®¡ç®—å™¨", 
        "è®¡ç®—æœº": "è®¡ç®—å™¨",
        "è®°äº‹ç‰ˆ": "è®°äº‹æœ¬",
        "æ–‡ä»¶ç®¡ç†": "æ–‡ä»¶ç®¡ç†å™¨",
        "èµ„æºç®¡ç†": "æ–‡ä»¶ç®¡ç†å™¨",
        "ä»»åŠ¡ç®¡ç†": "ä»»åŠ¡ç®¡ç†å™¨",
        "æ§åˆ¶ç‰ˆ": "æ§åˆ¶é¢æ¿",
        "å“”å“©å“”å“©": "bilibili",
        "Bç«™": "bilibili",
        "bç«™": "bilibili",
        "ç½‘æ˜“äº‘": "ç½‘æ˜“äº‘éŸ³ä¹",
        "è°·æ­Œ": "google",
        "ç™¾åº¦ä¸€ä¸‹": "ç™¾åº¦",
        # æ–°å¢çš„å¸¸è§é”™è¯¯
        "å¤§å¼€": "æ‰“å¼€",
        "æ‰“å¼€æµè§ˆå™¨è®¿é—®": "æ‰“å¼€",
        "æµè§ˆå™¨è®¿é—®": "æ‰“å¼€",
        "è®¿é—®çŸ¥ä¹ç½‘ç«™": "çŸ¥ä¹",
        "çŸ¥ä¹ç½‘ç«™": "çŸ¥ä¹",
        "ç™¾åº¦ç½‘ç«™": "ç™¾åº¦",
        "è°·æ­Œç½‘ç«™": "è°·æ­Œ",
        "å¾®åšç½‘ç«™": "å¾®åš",
        "è®¡ç®—æœºå™¨": "è®¡ç®—å™¨",
        "è®°äº‹ç°¿": "è®°äº‹æœ¬",
        "æ–‡æœ¬ç¼–è¾‘": "è®°äº‹æœ¬"
    }
    
    corrected_text = text
    for wrong, correct in corrections.items():
        corrected_text = corrected_text.replace(wrong, correct)
    
    return corrected_text

def smart_command_detection(text: str) -> tuple[bool, str, str]:
    """æ™ºèƒ½æŒ‡ä»¤æ£€æµ‹ - è¿”å›(æ˜¯å¦ä¸ºæŒ‡ä»¤, æŒ‡ä»¤ç±»å‹, ç›®æ ‡)"""
    text = preprocess_chinese_text(text.strip())
    text_lower = text.lower()
    
    # æ£€æŸ¥æ¯ç§æŒ‡ä»¤ç±»å‹
    for cmd_type, config in COMMAND_PATTERNS.items():
        keywords = config["keywords"]
        targets = config["targets"]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
        has_keyword = any(keyword in text for keyword in keywords)
        
        if has_keyword:
            # æ£€æŸ¥ç›®æ ‡
            for target_name, target_aliases in targets.items():
                if any(alias in text_lower for alias in target_aliases):
                    return True, cmd_type, target_name
    
    # ç‰¹æ®Šæƒ…å†µï¼šç›´æ¥è¯´ç›®æ ‡åç§° (æ‰©å±•åˆ°æ‰€æœ‰æŒ‡ä»¤ç±»å‹)
    for cmd_type, config in COMMAND_PATTERNS.items():
        for target_name, target_aliases in config["targets"].items():
            if any(alias in text_lower for alias in target_aliases):
                # å¦‚æœæ–‡æœ¬å¾ˆçŸ­ä¸”ä¸»è¦æ˜¯ç›®æ ‡åç§°ï¼Œè®¤ä¸ºæ˜¯æŒ‡ä»¤
                if len(text.strip()) <= 10:
                    return True, cmd_type, target_name
    
    return False, "", ""

@app.post("/transcribe", response_model=dict)
async def transcribe_audio(audio_file: UploadFile = File(...)):
    """ä¼˜åŒ–çš„è¯­éŸ³è½¬æ–‡å­—æ¥å£"""
    if not whisper_model:
        raise HTTPException(status_code=500, detail="Whisperæ¨¡å‹æœªåŠ è½½")
    
    try:
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            content = await audio_file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        # ä¼˜åŒ–çš„Whisperè½¬å½•å‚æ•°
        logger.info("å¼€å§‹è½¬å½•éŸ³é¢‘...")
        result = whisper_model.transcribe(
            temp_file_path,
            language="zh",  # å¼ºåˆ¶ä¸­æ–‡
            initial_prompt="ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„è½¬å½•ï¼Œè¯·å‡†ç¡®è¯†åˆ«åº”ç”¨ç¨‹åºåç§°å¦‚è®°äº‹æœ¬ã€è®¡ç®—å™¨ç­‰ã€‚",
            temperature=0.0,  # é™ä½éšæœºæ€§
            beam_size=5,      # å¢åŠ beam search
            best_of=5,        # å¤šæ¬¡å°è¯•å–æœ€ä½³
            fp16=torch.cuda.is_available(),  # GPUæ—¶ä½¿ç”¨fp16åŠ é€Ÿ
            condition_on_previous_text=False,  # ä¸ä¾èµ–å‰æ–‡
            no_speech_threshold=0.6,
            logprob_threshold=-1.0,
            compression_ratio_threshold=2.4
        )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_file_path)
        
        # é¢„å¤„ç†è½¬å½•ç»“æœ
        transcribed_text = preprocess_chinese_text(result["text"].strip())
        logger.info(f"è½¬å½•ç»“æœ: {transcribed_text}")
        
        # æ™ºèƒ½æŒ‡ä»¤æ£€æµ‹
        is_command, cmd_type, target = smart_command_detection(transcribed_text)
        
        return {
            "success": True,
            "transcribed_text": transcribed_text,
            "language": result.get("language", "zh"),
            "is_command": is_command,
            "command_type": cmd_type,
            "command_target": target,
            "confidence": result.get("avg_logprob", 0)
        }
        
    except Exception as e:
        logger.error(f"è½¬å½•é”™è¯¯: {str(e)}")
        if 'temp_file_path' in locals():
            try:
                os.unlink(temp_file_path)
            except:
                pass
        raise HTTPException(status_code=500, detail=f"è½¬å½•å¤±è´¥: {str(e)}")

def execute_enhanced_command(cmd_type: str, target: str, original_text: str) -> Optional[str]:
    """æ‰§è¡Œå¢å¼ºçš„ç³»ç»Ÿå‘½ä»¤"""
    system = platform.system().lower()
    
    try:
        if cmd_type == "åº”ç”¨ç¨‹åº":
            if system == 'windows':
                commands = {
                    "è®°äº‹æœ¬": "notepad",
                    "è®¡ç®—å™¨": "calc", 
                    "ç”»å›¾": "mspaint",
                    "æ–‡ä»¶ç®¡ç†å™¨": "explorer",
                    "æµè§ˆå™¨": "start msedge",
                    "ä»»åŠ¡ç®¡ç†å™¨": "taskmgr",
                    "æ§åˆ¶é¢æ¿": "control",
                    "å‘½ä»¤æç¤ºç¬¦": "cmd",
                    "PowerShell": "powershell"
                }
                
                if target in commands:
                    subprocess.run(commands[target], shell=True)
                    return f"âœ… å·²ä¸ºæ‚¨æ‰“å¼€{target}"
        
        elif cmd_type == "ç½‘ç«™":
            urls = {
                "ç™¾åº¦": "https://www.baidu.com",
                "è°·æ­Œ": "https://www.google.com", 
                "çŸ¥ä¹": "https://www.zhihu.com",
                "å¾®åš": "https://weibo.com",
                "å“”å“©å“”å“©": "https://www.bilibili.com",
                "æ·˜å®": "https://www.taobao.com",
                "äº¬ä¸œ": "https://www.jd.com",
                "GitHub": "https://github.com",
                "YouTube": "https://www.youtube.com",
                "ç½‘æ˜“äº‘éŸ³ä¹": "https://music.163.com"
            }
            
            if target in urls:
                if system == 'windows':
                    os.startfile(urls[target])
                    return f"âœ… å·²ä¸ºæ‚¨æ‰“å¼€{target}"
                else:
                    return f"æ£€æµ‹åˆ°æ‰“å¼€ç½‘ç«™å‘½ä»¤: {urls[target]}"
        
        elif cmd_type == "ç³»ç»Ÿæ“ä½œ":
            if system == 'windows':
                operations = {
                    "å…³æœº": "shutdown /s /t 0",
                    "é‡å¯": "shutdown /r /t 0", 
                    "æ³¨é”€": "shutdown /l",
                    "ä¼‘çœ ": "rundll32.exe powrprof.dll,SetSuspendState 0,1,0",  # æ·»åŠ ä¼‘çœ å‘½ä»¤
                    "é”å±": "rundll32.exe user32.dll,LockWorkStation",
                    "æˆªå›¾": "snippingtool"
                }
                
                if target in operations:
                    try:
                        cmd = operations[target]
                        logger.info(f"æ‰§è¡Œç³»ç»Ÿæ“ä½œ: {target}, å‘½ä»¤: {cmd}")
                        
                        # å±é™©æ“ä½œéœ€è¦ç¡®è®¤
                        if target in ["å…³æœº", "é‡å¯", "æ³¨é”€"]:
                            return f"âš ï¸ æ£€æµ‹åˆ°{target}å‘½ä»¤ï¼Œè¯·æ‰‹åŠ¨ç¡®è®¤æ‰§è¡Œ"
                        
                        # ç‰¹æ®Šå¤„ç†ä¸åŒç±»å‹çš„ç³»ç»Ÿæ“ä½œ
                        if target == "ä¼‘çœ ":
                            try:
                                logger.info("å¼€å§‹æ‰§è¡Œä¼‘çœ æ“ä½œ")
                                
                                # é€‰æ‹©æœ€å¯é çš„ä¼‘çœ æ–¹æ³•ï¼Œåªå°è¯•ä¸€æ¬¡
                                # ä¼˜å…ˆä½¿ç”¨ shutdown /hï¼Œè¿™æ˜¯æœ€æ ‡å‡†å’Œå¯é çš„æ–¹æ³•
                                hibernate_cmd = "shutdown /h"
                                
                                logger.info(f"æ‰§è¡Œä¼‘çœ å‘½ä»¤: {hibernate_cmd}")
                                
                                # ä½¿ç”¨ Popen å¼‚æ­¥æ‰§è¡Œï¼Œé¿å…ç­‰å¾…è¿”å›å€¼
                                # å› ä¸ºä¼‘çœ å‘½ä»¤æ‰§è¡Œåç³»ç»Ÿä¼šç«‹å³æš‚åœï¼Œæ— æ³•è¿”å›ç»“æœ
                                import subprocess
                                process = subprocess.Popen(
                                    hibernate_cmd,
                                    shell=True,
                                    stdout=subprocess.DEVNULL,
                                    stderr=subprocess.DEVNULL
                                )
                                
                                # ä¸ç­‰å¾…è¿›ç¨‹ç»“æŸï¼Œç«‹å³è¿”å›æˆåŠŸ
                                logger.info("ä¼‘çœ å‘½ä»¤å·²å‘é€ï¼Œç³»ç»Ÿå³å°†è¿›å…¥ä¼‘çœ çŠ¶æ€")
                                return f"âœ… ç³»ç»Ÿæ­£åœ¨è¿›å…¥ä¼‘çœ çŠ¶æ€"
                                
                            except Exception as hibernate_e:
                                logger.error(f"ä¼‘çœ å‘½ä»¤æ‰§è¡Œå¼‚å¸¸: {hibernate_e}")
                                
                                # å¦‚æœä¸»æ–¹æ³•å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
                                try:
                                    logger.info("å°è¯•å¤‡ç”¨ä¼‘çœ æ–¹æ³•")
                                    backup_cmd = "rundll32.exe powrprof.dll,SetSuspendState 0,1,0"
                                    
                                    process = subprocess.Popen(
                                        backup_cmd,
                                        shell=True,
                                        stdout=subprocess.DEVNULL,
                                        stderr=subprocess.DEVNULL
                                    )
                                    
                                    logger.info("å¤‡ç”¨ä¼‘çœ å‘½ä»¤å·²å‘é€")
                                    return f"âœ… ç³»ç»Ÿæ­£åœ¨è¿›å…¥ä¼‘çœ çŠ¶æ€"
                                    
                                except Exception as backup_e:
                                    logger.error(f"å¤‡ç”¨ä¼‘çœ æ–¹æ³•ä¹Ÿå¤±è´¥: {backup_e}")
                                    return f"âŒ ä¼‘çœ å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿä¼‘çœ è®¾ç½®æˆ–æ‰‹åŠ¨æŒ‰ç”µæºé”®é€‰æ‹©ä¼‘çœ "
                        
                        elif target == "é”å±":
                            try:
                                logger.info("å¼€å§‹æ‰§è¡Œé”å±æ“ä½œ")
                                
                                # æ–¹æ³•1: ä½¿ç”¨Windows API (æœ€å¯é )
                                try:
                                    import ctypes
                                    
                                    logger.info("ä½¿ç”¨Windows APIé”å±")
                                    user32 = ctypes.windll.user32
                                    result = user32.LockWorkStation()
                                    
                                    if result != 0:
                                        logger.info("Windows APIé”å±æˆåŠŸ")
                                        return f"âœ… å±å¹•å·²é”å®š"
                                    else:
                                        logger.warning("Windows APIé”å±å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•")
                                        
                                except Exception as api_e:
                                    logger.warning(f"Windows APIé”å±å¼‚å¸¸: {api_e}")
                                
                                # æ–¹æ³•2: ä½¿ç”¨rundll32å‘½ä»¤ (å¤‡ç”¨æ–¹æ³•)
                                try:
                                    logger.info("ä½¿ç”¨rundll32å‘½ä»¤é”å±")
                                    
                                    result = subprocess.run(
                                        "rundll32.exe user32.dll,LockWorkStation",
                                        shell=True,
                                        timeout=3,
                                        check=False
                                    )
                                    
                                    logger.info(f"rundll32é”å±æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {result.returncode}")
                                    
                                    # rundll32è¿”å›0è¡¨ç¤ºæˆåŠŸ
                                    if result.returncode == 0:
                                        return f"âœ… å±å¹•å·²é”å®š"
                                    else:
                                        logger.warning("rundll32é”å±å¤±è´¥ï¼Œå°è¯•æœ€åçš„æ–¹æ³•")
                                        
                                except subprocess.TimeoutExpired:
                                    logger.info("rundll32é”å±è¶…æ—¶ï¼Œä½†å¯èƒ½å·²æˆåŠŸ")
                                    return f"âœ… å±å¹•å·²é”å®š"
                                except Exception as cmd_e:
                                    logger.warning(f"rundll32é”å±å¼‚å¸¸: {cmd_e}")
                                
                                # æ–¹æ³•3: ä½¿ç”¨PowerShell (æœ€åçš„å¤‡ç”¨)
                                try:
                                    logger.info("ä½¿ç”¨PowerShellé”å±")
                                    
                                    result = subprocess.run(
                                        'powershell -Command "rundll32.exe user32.dll,LockWorkStation"',
                                        shell=True,
                                        timeout=3,
                                        check=False
                                    )
                                    
                                    logger.info(f"PowerShellé”å±æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {result.returncode}")
                                    
                                    if result.returncode == 0:
                                        return f"âœ… å±å¹•å·²é”å®š"
                                    else:
                                        logger.error("PowerShellé”å±ä¹Ÿå¤±è´¥")
                                        
                                except subprocess.TimeoutExpired:
                                    logger.info("PowerShellé”å±è¶…æ—¶ï¼Œä½†å¯èƒ½å·²æˆåŠŸ")
                                    return f"âœ… å±å¹•å·²é”å®š"
                                except Exception as ps_e:
                                    logger.error(f"PowerShellé”å±å¼‚å¸¸: {ps_e}")
                                
                                # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
                                logger.error("æ‰€æœ‰é”å±æ–¹æ³•éƒ½å¤±è´¥")
                                return f"âŒ é”å±å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æŒ‰ Win+L é”å±"
                                
                            except Exception as lock_e:
                                logger.error(f"é”å±æ“ä½œå¼‚å¸¸: {lock_e}")
                                return f"âŒ é”å±å¤±è´¥: {str(lock_e)}"
                        
                        elif target == "æˆªå›¾":
                            try:
                                # å°è¯•å¤šç§æˆªå›¾æ–¹æ³•
                                screenshot_commands = [
                                    "snippingtool",  # Windowsæˆªå›¾å·¥å…·
                                    "ms-screenclip:",  # Windows 10/11æˆªå›¾
                                    "start ms-screenclip:",  # å¤‡ç”¨æ–¹æ³•
                                ]
                                
                                success = False
                                for screenshot_cmd in screenshot_commands:
                                    try:
                                        result = subprocess.run(
                                            screenshot_cmd, 
                                            shell=True, 
                                            capture_output=True,
                                            text=True,
                                            timeout=5
                                        )
                                        
                                        if result.returncode == 0:
                                            success = True
                                            logger.info(f"æˆªå›¾å·¥å…·å¯åŠ¨æˆåŠŸ: {screenshot_cmd}")
                                            break
                                        else:
                                            logger.warning(f"æˆªå›¾å‘½ä»¤å¤±è´¥: {screenshot_cmd}, é”™è¯¯: {result.stderr}")
                                            
                                    except Exception as inner_e:
                                        logger.warning(f"æˆªå›¾å‘½ä»¤å¼‚å¸¸: {screenshot_cmd}, é”™è¯¯: {inner_e}")
                                        continue
                                
                                if success:
                                    return f"âœ… æˆªå›¾å·¥å…·å·²å¯åŠ¨"
                                else:
                                    # æœ€åå°è¯•ä½¿ç”¨Print Screené”®
                                    logger.info("å°è¯•æ¨¡æ‹ŸPrint Screené”®")
                                    return f"âš ï¸ æˆªå›¾å·¥å…·å¯åŠ¨å¯èƒ½å¤±è´¥ï¼Œè¯·å°è¯•æŒ‰Print Screené”®"
                                    
                            except Exception as screenshot_e:
                                logger.error(f"æˆªå›¾å¤±è´¥: {screenshot_e}")
                                return f"âŒ æˆªå›¾å¤±è´¥: {str(screenshot_e)}"
                        
                        else:
                            # å…¶ä»–ç³»ç»Ÿæ“ä½œ
                            result = subprocess.run(
                                cmd, 
                                shell=True, 
                                capture_output=True, 
                                text=True,
                                timeout=10
                            )
                            
                            if result.returncode == 0:
                                logger.info(f"ç³»ç»Ÿæ“ä½œæˆåŠŸ: {target}")
                                return f"âœ… å·²æ‰§è¡Œ{target}"
                            else:
                                logger.warning(f"ç³»ç»Ÿæ“ä½œå¤±è´¥: {target}, é”™è¯¯: {result.stderr}")
                                return f"âš ï¸ {target}æ‰§è¡Œå¯èƒ½å¤±è´¥: {result.stderr}"
                                
                    except subprocess.TimeoutExpired:
                        logger.warning(f"ç³»ç»Ÿæ“ä½œè¶…æ—¶: {target}")
                        return f"âš ï¸ {target}æ‰§è¡Œè¶…æ—¶ï¼Œä½†å¯èƒ½å·²ç”Ÿæ•ˆ"
                    except Exception as e:
                        logger.error(f"ç³»ç»Ÿæ“ä½œå¼‚å¸¸: {target}, é”™è¯¯: {e}")
                        return f"âŒ {target}æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    except Exception as e:
        logger.error(f"æ‰§è¡Œå‘½ä»¤é”™è¯¯: {str(e)}")
        return f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    return None

@app.post("/process", response_model=VoiceResponse)
async def process_voice_command(request: VoiceRequest):
    """å¤„ç†è¯­éŸ³å‘½ä»¤æ¥å£"""
    try:
        text = request.text
        logger.info(f"å¤„ç†å‘½ä»¤: {text}")
        
        # æ™ºèƒ½æŒ‡ä»¤æ£€æµ‹
        is_command, cmd_type, target = smart_command_detection(text)
        logger.info(f"æŒ‡ä»¤æ£€æµ‹ç»“æœ: is_command={is_command}, cmd_type={cmd_type}, target={target}")
        
        # æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ (ä¼˜å…ˆæ‰§è¡Œï¼Œä¸ä¾èµ–AIå›å¤)
        command_executed = False
        command_result = None
        
        if request.execute_commands and is_command:
            logger.info(f"å¼€å§‹æ‰§è¡ŒæŒ‡ä»¤: {cmd_type} - {target}")
            command_result = execute_enhanced_command(cmd_type, target, text)
            if command_result and not command_result.startswith("æŠ±æ­‰"):
                command_executed = True
                logger.info(f"æŒ‡ä»¤æ‰§è¡ŒæˆåŠŸ: {command_result}")
            else:
                logger.warning(f"æŒ‡ä»¤æ‰§è¡Œå¤±è´¥: {command_result}")
        
        # è·å–AIå›å¤ (åªæœ‰éæŒ‡ä»¤æ‰éœ€è¦AIå›å¤)
        ai_response = "æŒ‡ä»¤å·²å¤„ç†" if is_command else "æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚..."
        
        # åªæœ‰æ™®é€šå¯¹è¯æ‰è°ƒç”¨AIæ¨¡å‹ï¼Œé¿å…GPUå†…å­˜å†²çª
        if not is_command:
            try:
                # ä¸ºäº†é¿å…GPUå†…å­˜å†²çªï¼Œæš‚æ—¶ç¦ç”¨AIå›å¤
                # ai_response = await get_ai_response(text)
                ai_response = "è¯­éŸ³æŒ‡ä»¤æ¨¡å¼ä¸‹æš‚ä¸æ”¯æŒAIå¯¹è¯ï¼Œè¯·ç›´æ¥åœ¨èŠå¤©æ¡†ä¸­è¾“å…¥æ–‡å­—è¿›è¡ŒAIå¯¹è¯"
            except Exception as e:
                logger.warning(f"AIå›å¤è·å–å¤±è´¥: {e}")
                ai_response = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
        
        return VoiceResponse(
            transcribed_text=text,
            ai_response=ai_response,
            command_executed=command_executed,
            command_result=command_result,
            command_type=cmd_type if is_command else None
        )
        
    except Exception as e:
        logger.error(f"å¤„ç†å‘½ä»¤é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†å¤±è´¥: {str(e)}")

async def get_ai_response(text: str) -> str:
    """è·å–AIå›å¤"""
    models_to_try = ['minicpm-v:latest', 'qwen3:14b', 'deepseek-r1:14b', 'llama3.2-vision:11b']
    
    for model_name in models_to_try:
        try:
            logger.info(f"å°è¯•æ¨¡å‹: {model_name}")
            response = requests.post(
                f"{OLLAMA_API_BASE}/generate",
                json={
                    "model": model_name,
                    "prompt": f"è¯·ç”¨ä¸­æ–‡å›ç­”è¿™ä¸ªé—®é¢˜: {text}",
                    "stream": False
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                ai_response = result['response'].strip()
                logger.info(f"æˆåŠŸä½¿ç”¨æ¨¡å‹: {model_name}")
                return ai_response
            else:
                logger.warning(f"æ¨¡å‹ {model_name} HTTPé”™è¯¯: {response.status_code}")
                continue
                
        except Exception as e:
            logger.warning(f"æ¨¡å‹ {model_name} å¤±è´¥: {str(e)}")
            continue
    
    return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è¿æ¥åˆ°AIæ¨¡å‹ã€‚è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œå¹¶ä¸”å·²å®‰è£…æ¨¡å‹ã€‚"

if __name__ == "__main__":
    from config import Config
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    Config.print_config()
    
    # ä½¿ç”¨é…ç½®å¯åŠ¨æœåŠ¡
    uvicorn.run(app, host=Config.API_HOST, port=Config.API_PORT)
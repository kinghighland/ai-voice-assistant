import whisper
import pyttsx3
import pyaudio
import wave
import pyautogui
import subprocess
import ollama
import requests
import os
import platform
import keyboard
import threading
import time

# åˆå§‹åŒ–
# ä½¿ç”¨æ›´å¤§çš„Whisperæ¨¡å‹ä»¥æé«˜ä¸­æ–‡è¯†åˆ«å‡†ç¡®ç‡
print("æ­£åœ¨åŠ è½½Whisperæ¨¡å‹...")
model = whisper.load_model("medium")  # ä»baseå‡çº§åˆ°mediumï¼Œæ›´å¥½çš„ä¸­æ–‡æ”¯æŒ
engine = pyttsx3.init()

# è®¾ç½®ä¸­æ–‡è¯­éŸ³
voices = engine.getProperty('voices')
for voice in voices:
    if 'chinese' in voice.name.lower() or 'mandarin' in voice.name.lower():
        engine.setProperty('voice', voice.id)
        break
engine.setProperty('rate', 150)  # è¯­é€Ÿè°ƒæ…¢ä¸€ç‚¹

def record_audio_with_key_control(filename="input.wav", max_duration=30):
    """æŒ‰ä½Enterå½•éŸ³ï¼Œæ¾å¼€åœæ­¢çš„å½•éŸ³å‡½æ•°"""
    chunk = 4096
    format = pyaudio.paInt16
    channels = 1
    rate = 44100
    
    print("ğŸ¤ æŒ‰ä½Enteré”®å¼€å§‹å½•éŸ³ï¼Œæ¾å¼€åœæ­¢...")
    
    # ç­‰å¾…ç”¨æˆ·æŒ‰ä¸‹Enteré”®
    while True:
        if keyboard.is_pressed('enter'):
            break
        time.sleep(0.01)
    
    print("ğŸ¤ å½•éŸ³ä¸­ï¼Œæ¾å¼€Enteré”®åœæ­¢...")
    
    p = pyaudio.PyAudio()
    
    # é€‰æ‹©æœ€ä½³éŸ³é¢‘è¾“å…¥è®¾å¤‡
    input_device_index = None
    for i in range(p.get_device_count()):
        device_info = p.get_device_info_by_index(i)
        if device_info['maxInputChannels'] > 0:
            input_device_index = i
            break
    
    stream = p.open(
        format=format,
        channels=channels,
        rate=rate,
        input=True,
        input_device_index=input_device_index,
        frames_per_buffer=chunk
    )
    
    frames = []
    start_time = time.time()
    
    while keyboard.is_pressed('enter'):
        try:
            data = stream.read(chunk, exception_on_overflow=False)
            frames.append(data)
            
            # æ˜¾ç¤ºå½•éŸ³æ—¶é•¿
            elapsed = time.time() - start_time
            print(f"\rğŸ¤ å½•éŸ³ä¸­... {elapsed:.1f}ç§’", end="", flush=True)
            
            # é˜²æ­¢å½•éŸ³æ—¶é—´è¿‡é•¿
            if elapsed > max_duration:
                print(f"\nâš ï¸ å½•éŸ³æ—¶é—´è¶…è¿‡{max_duration}ç§’ï¼Œè‡ªåŠ¨åœæ­¢")
                break
                
        except Exception as e:
            print(f"\nå½•éŸ³é”™è¯¯: {e}")
            break
    
    print("\nâœ… å½•éŸ³å®Œæˆï¼Œæ­£åœ¨å¤„ç†...")
    
    stream.stop_stream()
    stream.close()
    p.terminate()
    
    if not frames:
        print("âŒ æ²¡æœ‰å½•åˆ¶åˆ°éŸ³é¢‘æ•°æ®")
        return False
    
    # ä¿å­˜ä¸ºé«˜è´¨é‡WAVæ–‡ä»¶
    wf = wave.open(filename, 'wb')
    wf.setnchannels(channels)
    wf.setsampwidth(p.get_sample_size(format))
    wf.setframerate(rate)
    wf.writeframes(b''.join(frames))
    wf.close()
    
    return True

def process_command(text):
    # ä½¿ç”¨Ollamaå¤„ç†å‘½ä»¤ (HTTP API approach)
    try:
        print("Testing Ollama connection...")
        
        # Try different models in order of preference (using exact names from your system)
        models_to_try = ['minicpm-v:latest', 'qwen3:14b', 'deepseek-r1:14b', 'llama3.2-vision:11b']
        
        ai_response = ""
        for model_name in models_to_try:
            try:
                print(f"Trying model: {model_name}")
                
                # Use HTTP API directly
                OLLAMA_API_BASE = "http://localhost:11434/api"
                response = requests.post(
                    f"{OLLAMA_API_BASE}/generate",
                    json={
                        "model": model_name,
                        "prompt": f"è¯·ç”¨ä¸­æ–‡å›ç­”è¿™ä¸ªé—®é¢˜: {text}",
                        "stream": False
                    },
                    timeout=30
                )
                
                if response.status_code == 200:
                    result = response.json()
                    ai_response = result['response'].strip()
                    print(f"Successfully used model: {model_name}")
                    break
                else:
                    print(f"HTTP error {response.status_code} for model {model_name}")
                    continue
                    
            except Exception as model_error:
                print(f"Failed to use model {model_name}: {model_error}")
                continue
        
        if not ai_response:
            ai_response = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è¿æ¥åˆ°AIæ¨¡å‹ã€‚è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œå¹¶ä¸”å·²å®‰è£…æ¨¡å‹ã€‚"
        
        # æ§åˆ¶é€»è¾‘éƒ¨åˆ† - æ£€æŸ¥æ˜¯å¦åŒ…å«æ§åˆ¶å‘½ä»¤
        command_lower = text.lower()
        system = platform.system().lower()
        
        # æ£€æŸ¥æ‰“å¼€ç½‘ç«™çš„å‘½ä»¤
        if any(keyword in text for keyword in ["æ‰“å¼€", "è®¿é—®", "è¿›å…¥"]) and any(site in text for site in ["ç½‘ç«™", "ç½‘é¡µ"]):
            url = ""
            if "çŸ¥ä¹" in text:
                url = "https://www.zhihu.com"
            elif "ç™¾åº¦" in text:
                url = "https://www.baidu.com"
            elif "è°·æ­Œ" in text or "google" in command_lower:
                url = "https://www.google.com"
            elif "å¾®åš" in text:
                url = "https://weibo.com"
            elif "bilibili" in text or "bç«™" in text:
                url = "https://www.bilibili.com"
            elif "æ·˜å®" in text:
                url = "https://www.taobao.com"
            elif "äº¬ä¸œ" in text:
                url = "https://www.jd.com"
            elif "github" in command_lower:
                url = "https://github.com"
            
            if url and system == 'windows':
                try:
                    os.startfile(url)
                    return f"âœ… å·²ä¸ºæ‚¨æ‰“å¼€ {url}"
                except:
                    return f"âŒ æ— æ³•æ‰“å¼€ç½‘ç«™ {url}"
            elif url:
                return f"æ­£åœ¨å°è¯•æ‰“å¼€ {url}"
        
        # æ£€æŸ¥æ‰“å¼€æµè§ˆå™¨çš„å‘½ä»¤
        elif any(keyword in command_lower for keyword in ["open browser", "æ‰“å¼€æµè§ˆå™¨", "å¼€å¯æµè§ˆå™¨"]):
            if system == 'windows':
                try:
                    os.startfile("https://www.google.com")
                    return "âœ… å·²ä¸ºæ‚¨æ‰“å¼€æµè§ˆå™¨"
                except:
                    return "âŒ æ— æ³•æ‰“å¼€æµè§ˆå™¨"
            return "æ­£åœ¨å°è¯•æ‰“å¼€æµè§ˆå™¨"
        
        # æ£€æŸ¥æœç´¢å‘½ä»¤
        elif any(keyword in command_lower for keyword in ["search", "æœç´¢", "æŸ¥æ‰¾"]):
            search_term = ""
            if "search" in command_lower:
                search_term = command_lower.split("search")[-1].strip()
            elif "æœç´¢" in text:
                search_term = text.split("æœç´¢")[-1].strip()
            elif "æŸ¥æ‰¾" in text:
                search_term = text.split("æŸ¥æ‰¾")[-1].strip()
            
            if search_term and system == 'windows':
                try:
                    pyautogui.hotkey('win', 's')
                    pyautogui.write(search_term)
                    pyautogui.press('enter')
                    return f"âœ… å·²ä¸ºæ‚¨æœç´¢ï¼š{search_term}"
                except:
                    return f"âŒ æ— æ³•æ‰§è¡Œæœç´¢ï¼š{search_term}"
            return f"æ­£åœ¨æœç´¢ï¼š{search_term}"
        
        # æ£€æŸ¥æ‰“å¼€åº”ç”¨ç¨‹åºçš„å‘½ä»¤
        elif any(keyword in text for keyword in ["æ‰“å¼€", "å¯åŠ¨"]) and any(app in text for app in ["è®°äº‹æœ¬", "è®¡ç®—å™¨", "ç”»å›¾", "æ–‡ä»¶ç®¡ç†å™¨"]):
            if system == 'windows':
                try:
                    if "è®°äº‹æœ¬" in text:
                        subprocess.run("notepad", shell=True)
                        return "âœ… å·²ä¸ºæ‚¨æ‰“å¼€è®°äº‹æœ¬"
                    elif "è®¡ç®—å™¨" in text:
                        subprocess.run("calc", shell=True)
                        return "âœ… å·²ä¸ºæ‚¨æ‰“å¼€è®¡ç®—å™¨"
                    elif "ç”»å›¾" in text:
                        subprocess.run("mspaint", shell=True)
                        return "âœ… å·²ä¸ºæ‚¨æ‰“å¼€ç”»å›¾"
                    elif "æ–‡ä»¶ç®¡ç†å™¨" in text:
                        subprocess.run("explorer", shell=True)
                        return "âœ… å·²ä¸ºæ‚¨æ‰“å¼€æ–‡ä»¶ç®¡ç†å™¨"
                except:
                    return "âŒ æ— æ³•æ‰“å¼€åº”ç”¨ç¨‹åº"
        
        # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°æ§åˆ¶å‘½ä»¤ï¼Œè¿”å›AIå›ç­”
        return ai_response
        
    except Exception as e:
        print(f"Ollama connection error: {str(e)}")
        return f"Error processing command: {str(e)}"

# ä¸»å¾ªç¯
print("ğŸ™ï¸ è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨ï¼")
print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•ï¼šæŒ‰ä½Enteré”®å½•éŸ³ï¼Œæ¾å¼€åœæ­¢")
print("ğŸšª æŒ‰Ctrl+Cé€€å‡ºç¨‹åº")
print("-" * 50)

while True:
    try:
        # ä½¿ç”¨æ–°çš„æŒ‰é”®æ§åˆ¶å½•éŸ³
        if record_audio_with_key_control():
            # ä¼˜åŒ–çš„è½¬å½•è®¾ç½®ï¼Œä¸“é—¨é’ˆå¯¹ä¸­æ–‡
            print("ğŸ”„ æ­£åœ¨è½¬å½•è¯­éŸ³...")
            result = model.transcribe(
                "input.wav",
                language="zh",  # æŒ‡å®šä¸­æ–‡è¯­è¨€
                initial_prompt="ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„è½¬å½•ã€‚",  # ä¸­æ–‡æç¤ºè¯
                temperature=0.0,  # é™ä½éšæœºæ€§ï¼Œæé«˜å‡†ç¡®æ€§
                beam_size=5,  # ä½¿ç”¨beam searchæé«˜è´¨é‡
                best_of=5,  # å°è¯•å¤šæ¬¡å–æœ€ä½³ç»“æœ
                fp16=False  # åœ¨CPUä¸Šç¦ç”¨FP16
            )
            
            text = result["text"].strip()
            print(f"ğŸ—£ï¸ æ‚¨è¯´çš„æ˜¯: {text}")
            
            if not text:
                print("âŒ æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•")
                continue
            
            print("ğŸ¤– AIæ­£åœ¨æ€è€ƒ...")
            response = process_command(text)
            print(f"ğŸ¤– AIå›å¤: {response}")
            
            # è¯­éŸ³æ’­æŠ¥
            engine.say(response)
            engine.runAndWait()
            
            print("-" * 50)
        else:
            print("âŒ å½•éŸ³å¤±è´¥ï¼Œè¯·é‡è¯•")
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ å†è§ï¼")
        break
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        print("è¯·é‡è¯•...")